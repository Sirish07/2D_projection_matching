{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c3213aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtech\\anaconda3\\envs\\Sirish\\lib\\site-packages\\sklearn\\utils\\validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "no display found. Using non-interactive Agg backend\n"
     ]
    }
   ],
   "source": [
    "import startup\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import io\n",
    "import tensorflow.compat.v1 as tf\n",
    "from models import models\n",
    "import matplotlib\n",
    "if os.environ.get('DISPLAY','') == '':\n",
    "    print('no display found. Using non-interactive Agg backend')\n",
    "    matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from util.system import setup_environment\n",
    "from util.train import get_trainable_variables, get_learning_rate_origin, get_learning_rate, get_path\n",
    "from util.losses import regularization_loss\n",
    "from util.fs import mkdir_if_missing\n",
    "from util.data import tf_record_compression\n",
    "import tensorflow.contrib.slim as slim\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df8cd393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tf_records(cfg, serialized):\n",
    "    num_views = cfg.num_views\n",
    "    image_size = cfg.image_size\n",
    "\n",
    "    # A dictionary from TF-Example keys to tf.FixedLenFeature instance.\n",
    "    features = {\n",
    "        'name': tf.FixedLenFeature([1], tf.string),\n",
    "        'image': tf.FixedLenFeature([num_views, image_size, image_size, 3], tf.float32),\n",
    "        'mask': tf.FixedLenFeature([num_views, image_size, image_size, 1], tf.float32),\n",
    "        'inpoints':tf.FixedLenFeature([num_views, cfg.gt_point_n, 2], tf.float32),\n",
    "    }\n",
    "\n",
    "    if cfg.saved_camera:\n",
    "        features.update(\n",
    "            {'extrinsic': tf.FixedLenFeature([num_views, 4, 4], tf.float32),\n",
    "             'cam_pos': tf.FixedLenFeature([num_views, 3], tf.float32)})\n",
    "    if cfg.saved_depth:\n",
    "        features.update(\n",
    "            {'depth': tf.FixedLenFeature([num_views, image_size, image_size, 1], tf.float32)})\n",
    "\n",
    "    return tf.parse_single_example(serialized, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46f5c28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_plot(x, y, title):\n",
    "    \"\"\"Create a pyplot plot and save to buffer.\"\"\"\n",
    "    plt.figure()\n",
    "    plt.plot(x, y)\n",
    "    print(x.shape, y.shape)\n",
    "    plt.title(title)\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    return buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fd1cc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.config import merge_configs_recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "943f774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = merge_configs_recursive([{}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e06eb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = get_path(cfg)\n",
    "train_dir = os.path.join(train_dir, str(cfg.vox_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da55d51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../../Dataset/tf_records_new/03001627_train.tfrecords\n",
      "WARNING:tensorflow:Entity <function <lambda> at 0x0000022738C904C8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: ('EOF in multi-line statement', (4, 0))\n",
      "WARNING: Entity <function <lambda> at 0x0000022738C904C8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: ('EOF in multi-line statement', (4, 0))\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "split_name = 'train'\n",
    "dataset_file = os.path.join(\"../../../../Dataset/tf_records_new/\", f\"{cfg['synth_set']}_{split_name}.tfrecords\")\n",
    "print(dataset_file)\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(dataset_file, compression_type=tf_record_compression(cfg))\n",
    "dataset = dataset.map(lambda rec: parse_tf_records(cfg, rec), num_parallel_calls=4) \\\n",
    "        .batch(cfg.batch_size) \\\n",
    "        .prefetch(buffer_size=100) \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5e398fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mtech\\AppData\\Local\\Temp\\ipykernel_8748\\1464879332.py:1: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n"
     ]
    }
   ],
   "source": [
    "iterator = dataset.make_one_shot_iterator()\n",
    "train_data = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27ace0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'IteratorGetNext:5' shape=(?, 1) dtype=string>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3021ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Sirish\\2DPM EPCG\\2D_projection_matching\\2Dpm\\main/..\\data_preprocessor\\data_preprocessor.py:64: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "global_step = tf.train.get_or_create_global_step()\n",
    "model = models.ModelPointCloud(cfg, global_step)\n",
    "inputs = model.preprocess(train_data, cfg.step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d453acc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_to_keep = 120\n",
    "saver = tf.train.Saver(max_to_keep=max_to_keep)\n",
    "\n",
    "session_config = tf.ConfigProto(\n",
    "    log_device_placement=False)\n",
    "session_config.gpu_options.allow_growth = cfg.gpu_allow_growth\n",
    "session_config.gpu_options.per_process_gpu_memory_fraction = cfg.per_process_gpu_memory_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75880e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n",
      "(4, 128, 128, 3)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8748\\1366835747.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'images'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'images_1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'indices'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'valid_samples'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Sirish\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Sirish\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Sirish\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Sirish\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Sirish\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Sirish\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session(config=session_config) as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        tf.local_variables_initializer().run()\n",
    "        count = 0\n",
    "        while count <= 5:\n",
    "            images, images_1, indices, samples = sess.run([inputs['images'], inputs['images_1'], inputs['indices'], inputs['valid_samples']])\n",
    "            print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dfa9b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 128, 128, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5db96d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128, 128, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "740f1ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ True,  True,  True],\n",
       "         [ True,  True,  True],\n",
       "         [ True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True],\n",
       "         [ True,  True,  True],\n",
       "         [ True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True],\n",
       "         [ True,  True,  True],\n",
       "         [ True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True],\n",
       "         [ True,  True,  True],\n",
       "         [ True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True],\n",
       "         [ True,  True,  True],\n",
       "         [ True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True],\n",
       "         [ True,  True,  True],\n",
       "         [ True,  True,  True]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ True,  True,  True],\n",
       "         [ True,  True,  True],\n",
       "         [ True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True],\n",
       "         [ True,  True,  True],\n",
       "         [ True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True],\n",
       "         [ True,  True,  True],\n",
       "         [ True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True],\n",
       "         [ True,  True,  True],\n",
       "         [ True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True],\n",
       "         [ True,  True,  True],\n",
       "         [ True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True],\n",
       "         [ True,  True,  True],\n",
       "         [ True,  True,  True]]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0] == images_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb442d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "384124d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.random.choice(5, 4, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ded4f2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.expand_dims(ids, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19febe85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3],\n",
       "       [4],\n",
       "       [2],\n",
       "       [0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e26e3ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_ids = np.full((4, 1), 0, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d2a7cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a64b653",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ids = np.concatenate((batch_ids, ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc5df512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 3],\n",
       "       [0, 4],\n",
       "       [0, 2],\n",
       "       [0, 0]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "941d8b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.zeros((0, 2), dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55f4fc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.concatenate((out, full_ids), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d61a7ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 3],\n",
       "       [0, 4],\n",
       "       [0, 2],\n",
       "       [0, 0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "306cb0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 40, 40, 3) (4, 512)\n",
      "(1, 2048) (1, 40, 40, 12)\n",
      "WARNING:tensorflow:From /home/sirish/MTP_Thesis/2Dpm_EPCG/2D_projection_matching/2Dpm/main/../models/models.py:177: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "[<tf.Variable 'encoder/Conv/weights:0' shape=(5, 5, 3, 16) dtype=float32_ref>, <tf.Variable 'encoder/Conv/batch_normalization/gamma:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'encoder/Conv/batch_normalization/beta:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'encoder/Conv_1/weights:0' shape=(3, 3, 16, 32) dtype=float32_ref>, <tf.Variable 'encoder/Conv_1/batch_normalization/gamma:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'encoder/Conv_1/batch_normalization/beta:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'encoder/Conv_2/weights:0' shape=(3, 3, 32, 32) dtype=float32_ref>, <tf.Variable 'encoder/Conv_2/batch_normalization/gamma:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'encoder/Conv_2/batch_normalization/beta:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'encoder/Conv_3/weights:0' shape=(3, 3, 32, 64) dtype=float32_ref>, <tf.Variable 'encoder/Conv_3/batch_normalization/gamma:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'encoder/Conv_3/batch_normalization/beta:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'encoder/Conv_4/weights:0' shape=(3, 3, 64, 64) dtype=float32_ref>, <tf.Variable 'encoder/Conv_4/batch_normalization/gamma:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'encoder/Conv_4/batch_normalization/beta:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'encoder/Conv_5/weights:0' shape=(3, 3, 64, 128) dtype=float32_ref>, <tf.Variable 'encoder/Conv_5/batch_normalization/gamma:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'encoder/Conv_5/batch_normalization/beta:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'encoder/Conv_6/weights:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'encoder/Conv_6/batch_normalization/gamma:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'encoder/Conv_6/batch_normalization/beta:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'encoder/Conv_7/weights:0' shape=(3, 3, 128, 256) dtype=float32_ref>, <tf.Variable 'encoder/Conv_7/batch_normalization/gamma:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'encoder/Conv_7/batch_normalization/beta:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'encoder/Conv_8/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>, <tf.Variable 'encoder/Conv_8/batch_normalization/gamma:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'encoder/Conv_8/batch_normalization/beta:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'encoder/fully_connected/weights:0' shape=(4096, 1024) dtype=float32_ref>, <tf.Variable 'encoder/fully_connected/batch_normalization/gamma:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'encoder/fully_connected/batch_normalization/beta:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'encoder/fully_connected_1/weights:0' shape=(1024, 1024) dtype=float32_ref>, <tf.Variable 'encoder/fully_connected_1/batch_normalization/gamma:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'encoder/fully_connected_1/batch_normalization/beta:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'encoder/fully_connected_2/weights:0' shape=(1024, 1024) dtype=float32_ref>, <tf.Variable 'encoder/fully_connected_2/batch_normalization/gamma:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'encoder/fully_connected_2/batch_normalization/beta:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'encoder/fully_connected_3/weights:0' shape=(1024, 512) dtype=float32_ref>, <tf.Variable 'encoder/fully_connected_3/biases:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'decoder/fully_connected/weights:0' shape=(512, 1024) dtype=float32_ref>, <tf.Variable 'decoder/fully_connected/batch_normalization/gamma:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'decoder/fully_connected/batch_normalization/beta:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'decoder/fully_connected_1/weights:0' shape=(1024, 2048) dtype=float32_ref>, <tf.Variable 'decoder/fully_connected_1/batch_normalization/gamma:0' shape=(2048,) dtype=float32_ref>, <tf.Variable 'decoder/fully_connected_1/batch_normalization/beta:0' shape=(2048,) dtype=float32_ref>, <tf.Variable 'decoder/fully_connected_2/weights:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'decoder/fully_connected_2/batch_normalization/gamma:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'decoder/fully_connected_2/batch_normalization/beta:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'decoder/Conv2d_transpose/weights:0' shape=(3, 3, 192, 256) dtype=float32_ref>, <tf.Variable 'decoder/Conv2d_transpose/batch_normalization/gamma:0' shape=(192,) dtype=float32_ref>, <tf.Variable 'decoder/Conv2d_transpose/batch_normalization/beta:0' shape=(192,) dtype=float32_ref>, <tf.Variable 'decoder/Conv2d_transpose_1/weights:0' shape=(3, 3, 128, 192) dtype=float32_ref>, <tf.Variable 'decoder/Conv2d_transpose_1/batch_normalization/gamma:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'decoder/Conv2d_transpose_1/batch_normalization/beta:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'decoder/Conv2d_transpose_2/weights:0' shape=(3, 3, 96, 128) dtype=float32_ref>, <tf.Variable 'decoder/Conv2d_transpose_2/batch_normalization/gamma:0' shape=(96,) dtype=float32_ref>, <tf.Variable 'decoder/Conv2d_transpose_2/batch_normalization/beta:0' shape=(96,) dtype=float32_ref>, <tf.Variable 'decoder/Conv2d_transpose_3/weights:0' shape=(9, 9, 64, 96) dtype=float32_ref>, <tf.Variable 'decoder/Conv2d_transpose_3/batch_normalization/gamma:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'decoder/Conv2d_transpose_3/batch_normalization/beta:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'decoder/pixelconv/weight:0' shape=(1, 1, 64, 4) dtype=float32_ref>, <tf.Variable 'decoder/pixelconv/bias:0' shape=(1, 40, 40, 4) dtype=float32_ref>]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'getvalue'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-df6152fa095e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mloss_summary_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mpred_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_buf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mgt_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_buf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted_Image\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'getvalue'"
     ]
    }
   ],
   "source": [
    "model_fn = model.get_model_fn(\n",
    "    is_training=True, reuse=False, run_projection=True)\n",
    "\n",
    "outputs = model_fn(inputs)\n",
    "\n",
    "# train_scopes\n",
    "train_scopes = ['encoder', 'decoder']\n",
    "\n",
    "task_loss, c_loss, k_loss, de_loss = model.get_loss(inputs, outputs)\n",
    "reg_loss = regularization_loss(train_scopes, cfg)\n",
    "loss = task_loss\n",
    "\n",
    "learning_rate = get_learning_rate(cfg, global_step)\n",
    "tf.summary.scalar(\"Learning_Rate\", learning_rate)\n",
    "# Merge all Summaries\n",
    "summary_op = tf.summary.merge_all()\n",
    "\n",
    "\n",
    "var_list = get_trainable_variables(train_scopes)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train_op = optimizer.minimize(loss, global_step, var_list)\n",
    "\n",
    "# Epoch Loss summary\n",
    "tf.summary.scalar(\"Epoch_Loss\", per_epoch_loss)\n",
    "loss_summary_op = tf.summary.merge_all()\n",
    "\n",
    "pred_image = tf.image.decode_png(pred_buf.getvalue(), channels=4)\n",
    "gt_image = tf.image.decode_png(gt_buf.getvalue(), channels=4)\n",
    "tf.summary.image(\"Predicted_Image\", pred_image)\n",
    "tf.summary.image(\"Target_Image\", gt_image)\n",
    "im_summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d1ce5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1588d16",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'session_config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ee156c75ef23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession_config\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msummary_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mglobal_step_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'session_config' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=session_config) as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        tf.local_variables_initializer().run()\n",
    "        summary_writer = tf.summary.FileWriter(train_dir, flush_secs=10, graph=sess.graph)\n",
    "        global_step_val = 0\n",
    "        epoch_loss = 0\n",
    "        t0 = time.perf_counter()\n",
    "        while global_step_val <= cfg['max_number_of_steps']:\n",
    "            _, loss_val, global_step_val, summary, result, gtpoints = sess.run([train_op, loss, global_step, summary_op, outputs, inputs['inpoints']])\n",
    "            print(summary)\n",
    "            summary_writer.add_summary(summary, global_step_val)\n",
    "            temp = result['all_points']\n",
    "            points3d = result['points3D']\n",
    "            assert temp[0].all() == temp[1].all()\n",
    "            assert temp[0].all() == points3d.all()\n",
    "            is_nan = np.isnan(loss_val)\n",
    "            assert(not np.any(is_nan))\n",
    "            epoch_loss += loss_val\n",
    "            \n",
    "            if global_step_val % 2 == 0 and global_step_val > 0:\n",
    "                pred = result['test_o'][0]\n",
    "                gt = gtpoints[0]\n",
    "                \n",
    "                predx = np.reshape(pred[:, 0], [pred.shape[0], 1])\n",
    "                predy = np.reshape(pred[:, 1], [pred.shape[0], 1])\n",
    "\n",
    "                gtx = np.reshape(gt[:, 0], [gt.shape[0], 1])\n",
    "                gty = np.reshape(gt[:, 1], [gt.shape[0], 1])\n",
    "\n",
    "                pred_buf = gen_plot(predx, predy, \"Predicted Data\")\n",
    "                gt_buf = gen_plot(gtx, gty, \"Target Image\")\n",
    "                \n",
    "                im_summary = sess.run(im_summary_op, feed_dict = {pred_buf: pred_buf, gt_buf: gt_buf})\n",
    "                print(im_summary)\n",
    "                summary_writer.add_summary(im_summary, global_step_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c349f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957b5197",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
