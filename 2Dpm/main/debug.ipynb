{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c3213aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sirish/anaconda3/envs/2dpm/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sirish/anaconda3/envs/2dpm/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sirish/anaconda3/envs/2dpm/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sirish/anaconda3/envs/2dpm/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sirish/anaconda3/envs/2dpm/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sirish/anaconda3/envs/2dpm/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no display found. Using non-interactive Agg backend\n"
     ]
    }
   ],
   "source": [
    "import startup\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import io\n",
    "import tensorflow as tf\n",
    "from models import models\n",
    "import matplotlib\n",
    "if os.environ.get('DISPLAY','') == '':\n",
    "    print('no display found. Using non-interactive Agg backend')\n",
    "    matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from util.system import setup_environment\n",
    "from util.train import get_trainable_variables, get_learning_rate_origin, get_learning_rate, get_path\n",
    "from util.losses import regularization_loss\n",
    "from util.fs import mkdir_if_missing\n",
    "from util.data import tf_record_compression\n",
    "import tensorflow.contrib.slim as slim\n",
    "from scipy.io import loadmat\n",
    "tfsum = tf.contrib.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df8cd393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tf_records(cfg, serialized):\n",
    "    num_views = cfg.num_views\n",
    "    image_size = cfg.image_size\n",
    "\n",
    "    # A dictionary from TF-Example keys to tf.FixedLenFeature instance.\n",
    "    features = {\n",
    "        'name': tf.FixedLenFeature([1], tf.string),\n",
    "        'image': tf.FixedLenFeature([num_views, image_size, image_size, 3], tf.float32),\n",
    "        'mask': tf.FixedLenFeature([num_views, image_size, image_size, 1], tf.float32),\n",
    "        'inpoints':tf.FixedLenFeature([num_views, cfg.gt_point_n, 2], tf.float32),\n",
    "    }\n",
    "\n",
    "    if cfg.saved_camera:\n",
    "        features.update(\n",
    "            {'extrinsic': tf.FixedLenFeature([num_views, 4, 4], tf.float32),\n",
    "             'cam_pos': tf.FixedLenFeature([num_views, 3], tf.float32)})\n",
    "    if cfg.saved_depth:\n",
    "        features.update(\n",
    "            {'depth': tf.FixedLenFeature([num_views, image_size, image_size, 1], tf.float32)})\n",
    "\n",
    "    return tf.parse_single_example(serialized, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46f5c28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_plot(x, y, title):\n",
    "    \"\"\"Create a pyplot plot and save to buffer.\"\"\"\n",
    "    plt.figure()\n",
    "    plt.plot(x, y)\n",
    "    print(x.shape, y.shape)\n",
    "    plt.title(title)\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    return buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fd1cc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.config import merge_configs_recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "943f774c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sirish/MTP_Thesis/2Dpm_EPCG/2D_projection_matching/2Dpm/main/../util/config.py:46: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  yaml_cfg = edict(yaml.load(f))\n"
     ]
    }
   ],
   "source": [
    "cfg = merge_configs_recursive([{}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e06eb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = get_path(cfg)\n",
    "train_dir = os.path.join(train_dir, str(cfg.vox_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da55d51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../../Datasets/2Dpm/tf_records_new/03001627_train.tfrecords\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "split_name = 'train'\n",
    "dataset_file = os.path.join(\"../../../../Datasets/2Dpm/tf_records_new/\", f\"{cfg['synth_set']}_{split_name}.tfrecords\")\n",
    "print(dataset_file)\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(dataset_file, compression_type=tf_record_compression(cfg))\n",
    "dataset = dataset.map(lambda rec: parse_tf_records(cfg, rec), num_parallel_calls=4) \\\n",
    "        .batch(cfg.batch_size) \\\n",
    "        .prefetch(buffer_size=100) \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5e398fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = dataset.make_one_shot_iterator()\n",
    "train_data = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27ace0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'IteratorGetNext:5' shape=(?, 1) dtype=string>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3021ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Data Preprocessor\n",
      "Tensor(\"PyFunc:0\", dtype=int64) Tensor(\"PyFunc:1\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "global_step = tf.train.get_or_create_global_step()\n",
    "model = models.ModelPointCloud(cfg, global_step)\n",
    "inputs = model.preprocess(train_data, cfg.step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "295b34ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'item'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ce7ed91ea0ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'indices'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'item'"
     ]
    }
   ],
   "source": [
    "inputs['indices'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d453acc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_to_keep = 120\n",
    "saver = tf.train.Saver(max_to_keep=max_to_keep)\n",
    "\n",
    "session_config = tf.ConfigProto(\n",
    "    log_device_placement=False)\n",
    "session_config.gpu_options.allow_growth = cfg.gpu_allow_growth\n",
    "session_config.gpu_options.per_process_gpu_memory_fraction = cfg.per_process_gpu_memory_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75880e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [0 4]\n",
      " [0 0]\n",
      " [0 2]] [1. 1. 1. 1.]\n",
      "[[0 0]\n",
      " [0 4]\n",
      " [0 1]\n",
      " [0 2]] [1. 1. 1. 1.]\n",
      "[[0 3]\n",
      " [0 4]\n",
      " [0 1]\n",
      " [0 0]] [1. 1. 1. 1.]\n",
      "[[0 3]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 4]] [1. 1. 1. 1.]\n",
      "[[0 4]\n",
      " [0 3]\n",
      " [0 1]\n",
      " [0 2]] [1. 1. 1. 1.]\n",
      "[[0 1]\n",
      " [0 2]\n",
      " [0 4]\n",
      " [0 3]] [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=session_config) as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        tf.local_variables_initializer().run()\n",
    "        count = 0\n",
    "        while count <= 5:\n",
    "            indices, samples = sess.run([inputs['indices'], inputs['valid_samples']])\n",
    "            print(indices, samples)\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "384124d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.random.choice(5, 4, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ded4f2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.expand_dims(ids, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19febe85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3],\n",
       "       [4],\n",
       "       [2],\n",
       "       [0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e26e3ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_ids = np.full((4, 1), 0, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d2a7cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a64b653",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ids = np.concatenate((batch_ids, ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc5df512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 3],\n",
       "       [0, 4],\n",
       "       [0, 2],\n",
       "       [0, 0]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "941d8b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.zeros((0, 2), dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55f4fc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.concatenate((out, full_ids), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d61a7ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 3],\n",
       "       [0, 4],\n",
       "       [0, 2],\n",
       "       [0, 0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "306cb0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 40, 40, 3) (4, 512)\n",
      "(1, 2048) (1, 40, 40, 12)\n",
      "WARNING:tensorflow:From /home/sirish/MTP_Thesis/2Dpm_EPCG/2D_projection_matching/2Dpm/main/../models/models.py:177: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "[<tf.Variable 'encoder/Conv/weights:0' shape=(5, 5, 3, 16) dtype=float32_ref>, <tf.Variable 'encoder/Conv/batch_normalization/gamma:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'encoder/Conv/batch_normalization/beta:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'encoder/Conv_1/weights:0' shape=(3, 3, 16, 32) dtype=float32_ref>, <tf.Variable 'encoder/Conv_1/batch_normalization/gamma:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'encoder/Conv_1/batch_normalization/beta:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'encoder/Conv_2/weights:0' shape=(3, 3, 32, 32) dtype=float32_ref>, <tf.Variable 'encoder/Conv_2/batch_normalization/gamma:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'encoder/Conv_2/batch_normalization/beta:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'encoder/Conv_3/weights:0' shape=(3, 3, 32, 64) dtype=float32_ref>, <tf.Variable 'encoder/Conv_3/batch_normalization/gamma:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'encoder/Conv_3/batch_normalization/beta:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'encoder/Conv_4/weights:0' shape=(3, 3, 64, 64) dtype=float32_ref>, <tf.Variable 'encoder/Conv_4/batch_normalization/gamma:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'encoder/Conv_4/batch_normalization/beta:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'encoder/Conv_5/weights:0' shape=(3, 3, 64, 128) dtype=float32_ref>, <tf.Variable 'encoder/Conv_5/batch_normalization/gamma:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'encoder/Conv_5/batch_normalization/beta:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'encoder/Conv_6/weights:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'encoder/Conv_6/batch_normalization/gamma:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'encoder/Conv_6/batch_normalization/beta:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'encoder/Conv_7/weights:0' shape=(3, 3, 128, 256) dtype=float32_ref>, <tf.Variable 'encoder/Conv_7/batch_normalization/gamma:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'encoder/Conv_7/batch_normalization/beta:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'encoder/Conv_8/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>, <tf.Variable 'encoder/Conv_8/batch_normalization/gamma:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'encoder/Conv_8/batch_normalization/beta:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'encoder/fully_connected/weights:0' shape=(4096, 1024) dtype=float32_ref>, <tf.Variable 'encoder/fully_connected/batch_normalization/gamma:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'encoder/fully_connected/batch_normalization/beta:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'encoder/fully_connected_1/weights:0' shape=(1024, 1024) dtype=float32_ref>, <tf.Variable 'encoder/fully_connected_1/batch_normalization/gamma:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'encoder/fully_connected_1/batch_normalization/beta:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'encoder/fully_connected_2/weights:0' shape=(1024, 1024) dtype=float32_ref>, <tf.Variable 'encoder/fully_connected_2/batch_normalization/gamma:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'encoder/fully_connected_2/batch_normalization/beta:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'encoder/fully_connected_3/weights:0' shape=(1024, 512) dtype=float32_ref>, <tf.Variable 'encoder/fully_connected_3/biases:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'decoder/fully_connected/weights:0' shape=(512, 1024) dtype=float32_ref>, <tf.Variable 'decoder/fully_connected/batch_normalization/gamma:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'decoder/fully_connected/batch_normalization/beta:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'decoder/fully_connected_1/weights:0' shape=(1024, 2048) dtype=float32_ref>, <tf.Variable 'decoder/fully_connected_1/batch_normalization/gamma:0' shape=(2048,) dtype=float32_ref>, <tf.Variable 'decoder/fully_connected_1/batch_normalization/beta:0' shape=(2048,) dtype=float32_ref>, <tf.Variable 'decoder/fully_connected_2/weights:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'decoder/fully_connected_2/batch_normalization/gamma:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'decoder/fully_connected_2/batch_normalization/beta:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'decoder/Conv2d_transpose/weights:0' shape=(3, 3, 192, 256) dtype=float32_ref>, <tf.Variable 'decoder/Conv2d_transpose/batch_normalization/gamma:0' shape=(192,) dtype=float32_ref>, <tf.Variable 'decoder/Conv2d_transpose/batch_normalization/beta:0' shape=(192,) dtype=float32_ref>, <tf.Variable 'decoder/Conv2d_transpose_1/weights:0' shape=(3, 3, 128, 192) dtype=float32_ref>, <tf.Variable 'decoder/Conv2d_transpose_1/batch_normalization/gamma:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'decoder/Conv2d_transpose_1/batch_normalization/beta:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'decoder/Conv2d_transpose_2/weights:0' shape=(3, 3, 96, 128) dtype=float32_ref>, <tf.Variable 'decoder/Conv2d_transpose_2/batch_normalization/gamma:0' shape=(96,) dtype=float32_ref>, <tf.Variable 'decoder/Conv2d_transpose_2/batch_normalization/beta:0' shape=(96,) dtype=float32_ref>, <tf.Variable 'decoder/Conv2d_transpose_3/weights:0' shape=(9, 9, 64, 96) dtype=float32_ref>, <tf.Variable 'decoder/Conv2d_transpose_3/batch_normalization/gamma:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'decoder/Conv2d_transpose_3/batch_normalization/beta:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'decoder/pixelconv/weight:0' shape=(1, 1, 64, 4) dtype=float32_ref>, <tf.Variable 'decoder/pixelconv/bias:0' shape=(1, 40, 40, 4) dtype=float32_ref>]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'getvalue'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-df6152fa095e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mloss_summary_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mpred_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_buf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mgt_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_buf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted_Image\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'getvalue'"
     ]
    }
   ],
   "source": [
    "model_fn = model.get_model_fn(\n",
    "    is_training=True, reuse=False, run_projection=True)\n",
    "\n",
    "outputs = model_fn(inputs)\n",
    "\n",
    "# train_scopes\n",
    "train_scopes = ['encoder', 'decoder']\n",
    "\n",
    "task_loss, c_loss, k_loss, de_loss = model.get_loss(inputs, outputs)\n",
    "reg_loss = regularization_loss(train_scopes, cfg)\n",
    "loss = task_loss\n",
    "\n",
    "learning_rate = get_learning_rate(cfg, global_step)\n",
    "tf.summary.scalar(\"Learning_Rate\", learning_rate)\n",
    "# Merge all Summaries\n",
    "summary_op = tf.summary.merge_all()\n",
    "\n",
    "\n",
    "var_list = get_trainable_variables(train_scopes)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train_op = optimizer.minimize(loss, global_step, var_list)\n",
    "\n",
    "# Epoch Loss summary\n",
    "tf.summary.scalar(\"Epoch_Loss\", per_epoch_loss)\n",
    "loss_summary_op = tf.summary.merge_all()\n",
    "\n",
    "pred_image = tf.image.decode_png(pred_buf.getvalue(), channels=4)\n",
    "gt_image = tf.image.decode_png(gt_buf.getvalue(), channels=4)\n",
    "tf.summary.image(\"Predicted_Image\", pred_image)\n",
    "tf.summary.image(\"Target_Image\", gt_image)\n",
    "im_summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d1ce5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1588d16",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'session_config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ee156c75ef23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession_config\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msummary_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mglobal_step_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'session_config' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=session_config) as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        tf.local_variables_initializer().run()\n",
    "        summary_writer = tf.summary.FileWriter(train_dir, flush_secs=10, graph=sess.graph)\n",
    "        global_step_val = 0\n",
    "        epoch_loss = 0\n",
    "        t0 = time.perf_counter()\n",
    "        while global_step_val <= cfg['max_number_of_steps']:\n",
    "            _, loss_val, global_step_val, summary, result, gtpoints = sess.run([train_op, loss, global_step, summary_op, outputs, inputs['inpoints']])\n",
    "            print(summary)\n",
    "            summary_writer.add_summary(summary, global_step_val)\n",
    "            temp = result['all_points']\n",
    "            points3d = result['points3D']\n",
    "            assert temp[0].all() == temp[1].all()\n",
    "            assert temp[0].all() == points3d.all()\n",
    "            is_nan = np.isnan(loss_val)\n",
    "            assert(not np.any(is_nan))\n",
    "            epoch_loss += loss_val\n",
    "            \n",
    "            if global_step_val % 2 == 0 and global_step_val > 0:\n",
    "                pred = result['test_o'][0]\n",
    "                gt = gtpoints[0]\n",
    "                \n",
    "                predx = np.reshape(pred[:, 0], [pred.shape[0], 1])\n",
    "                predy = np.reshape(pred[:, 1], [pred.shape[0], 1])\n",
    "\n",
    "                gtx = np.reshape(gt[:, 0], [gt.shape[0], 1])\n",
    "                gty = np.reshape(gt[:, 1], [gt.shape[0], 1])\n",
    "\n",
    "                pred_buf = gen_plot(predx, predy, \"Predicted Data\")\n",
    "                gt_buf = gen_plot(gtx, gty, \"Target Image\")\n",
    "                \n",
    "                im_summary = sess.run(im_summary_op, feed_dict = {pred_buf: pred_buf, gt_buf: gt_buf})\n",
    "                print(im_summary)\n",
    "                summary_writer.add_summary(im_summary, global_step_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c349f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957b5197",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
